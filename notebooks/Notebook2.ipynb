{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8ebd99",
   "metadata": {},
   "source": [
    "#  Fear Emotional Analysis in *Pet Sematary* and *The Shining*  \n",
    "### Using a Custom Stephen-King-Inspired Fear Lexicon\n",
    "\n",
    "This notebook extracts and visualizes **fear intensity** across the two novels using a **fully custom, manually-crafted fear lexicon** designed specifically for Stephen King‚Äôs writing style.\n",
    "\n",
    "Why a custom lexicon?\n",
    "\n",
    "- Horror fiction uses *atmospheric* fear (shadows, silence, cold)  \n",
    "- Psychological fear appears through thoughts (madness, voices)  \n",
    "- King frequently expresses fear through *family trauma*  \n",
    "- Standard lexicons fail to cover these nuances  \n",
    "\n",
    "This approach creates a **unique, original analysis** suited for your NLP project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0cb1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acd5af",
   "metadata": {},
   "source": [
    "## Load Text Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afadac59",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PetSemetary_updated.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPetSemetary_updated.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     pet_text = f.read()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTheShining_updated.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'PetSemetary_updated.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"PetSemetary_updated.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    pet_text = f.read()\n",
    "\n",
    "with open(\"TheShining_updated.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    shining_text = f.read()\n",
    "\n",
    "    print(\"Files loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4892e",
   "metadata": {},
   "source": [
    "## Tokenize Text\n",
    "\n",
    "We lowercase and tokenize the novels to make them easier to process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "pet_tokens = word_tokenize(pet_text.lower())\n",
    "shining_tokens = word_tokenize(shining_text.lower())\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddd4b8",
   "metadata": {},
   "source": [
    "## Custom Fear Lexicon\n",
    "\n",
    "This lexicon combines:\n",
    "- **Core fear concepts**\n",
    "- **Atmospheric/environmental triggers**\n",
    "- **Psychological breakdown language**\n",
    "- **Family trauma indicators** (common in King)\n",
    "\n",
    "This allows deeper literary fear detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6a7450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear_words = { fear_lexicon.strip() for fear_lexicon in open(\"fear_lexicon.txt\", \"r\").readlines()\n",
    "} \n",
    "len(fear_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b49949",
   "metadata": {},
   "source": [
    "## Chunk the Novels into Narrative Segments\n",
    "\n",
    "We segment each novel into equal story chunks (e.g., 40).  \n",
    "This allows us to track fear progression over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d52554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created.\n"
     ]
    }
   ],
   "source": [
    "def chunk(tokens, n_chunks=40):\n",
    "    size = len(tokens) // n_chunks\n",
    "    return [tokens[i*size:(i+1)*size] for i in range(n_chunks)]\n",
    "\n",
    "pet_chunks = chunk(pet_tokens)\n",
    "shining_chunks = chunk(shining_tokens)\n",
    "print(\"Chunks created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386b79f",
   "metadata": {},
   "source": [
    "## Compute and Normalize Fear Scores for Each Segment\n",
    "\n",
    "Here we scan each segment and count how many fear lexicon words appear.  \n",
    "This gives us a fear score per story segment.\n",
    "Normalization (0‚Äì1 range) makes the two novels comparable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd96b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear scores calculated.\n",
      "Scores normalized.\n"
     ]
    }
   ],
   "source": [
    "def fear_score(chunk, lexicon):\n",
    "    return sum(1 for w in chunk if w in lexicon)\n",
    "\n",
    "pet_scores = [fear_score(chunk, fear_words) for chunk in pet_chunks]\n",
    "shining_scores = [fear_score(chunk, fear_words) for chunk in shining_chunks]\n",
    "print(\"Fear scores calculated.\")\n",
    "\n",
    "def normalize(xs):\n",
    "    xs = np.array(xs)\n",
    "    return (xs - xs.min()) / (xs.max() - xs.min() + 1e-6)\n",
    "\n",
    "pet_norm = normalize(pet_scores)\n",
    "shining_norm = normalize(shining_scores)\n",
    "print(\"Scores normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0569db",
   "metadata": {},
   "source": [
    "## Plot Fear Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897982eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pet_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plt.plot(\u001b[43mpet_norm\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mPet Sematary\u001b[39m\u001b[33m\"\u001b[39m, linewidth=\u001b[32m2\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(shining_norm, label=\u001b[33m\"\u001b[39m\u001b[33mThe Shining\u001b[39m\u001b[33m\"\u001b[39m, linewidth=\u001b[32m2\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mFear Intensity Across Narrative Progression\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pet_norm' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(pet_norm, label=\"Pet Sematary\", linewidth=2)\n",
    "plt.plot(shining_norm, label=\"The Shining\", linewidth=2)\n",
    "\n",
    "plt.title(\"Fear Intensity Across Narrative Progression\")\n",
    "plt.xlabel(\"Story Segment\")\n",
    "plt.ylabel(\"Normalized Fear Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a345b",
   "metadata": {},
   "source": [
    "# üß† Interpretation\n",
    "\n",
    "### **Pet Sematary**\n",
    "- Sharp spikes of fear  \n",
    "- Family-loss language strongly affects fear scores  \n",
    "- More sudden and traumatic fear moments  \n",
    "\n",
    "### **The Shining**\n",
    "- Slow, steady psychological escalation  \n",
    "- Heavy use of ambient fear (silence, shadows, cold)  \n",
    "- Fear rises with Jack‚Äôs mental deterioration  \n",
    "\n",
    "### **Conclusion**\n",
    "The custom lexicon reveals **different fear strategies**:\n",
    "- *Pet Sematary* ‚Üí visceral trauma  \n",
    "- *The Shining* ‚Üí psychological erosion  \n",
    "\n",
    "This supports the ‚ÄúLanguage of Fear‚Äù theme for our NLP project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
